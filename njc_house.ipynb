{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimbounce/BDSML_HousePrice/blob/main/njc_house.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coursework II -- Training hyperparameters\n",
        "\n",
        "The goal of the coursework is to modify a simple bit of numpy code that trains a network and measures the performance on a validation set for the MNist 1D dataset.\n",
        "\n",
        "In this coursework, you need to modify the **training hyperparameters** (only) to improve the performance over the current attempt. This could mean the training algorithm, learning rate, learning rate schedule, momentum term, initialization etc.  \n",
        "\n",
        "You must improve the performance by at least 2% to get full marks.\n",
        "\n",
        "You will need to upload three things to Moodle:\n",
        "1.   The image that this notebook saves (click the folder icon on the left on colab to download it)\n",
        "2.   The lines of code you changed\n",
        "3.   The whole notebook as a .ipynb file.  You can do this on the File menu"
      ],
      "metadata": {
        "id": "t9vk9Elugvmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import gdown"
      ],
      "metadata": {
        "id": "YrXWAH7sUWvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train: https://drive.google.com/file/d/10dPJKqwVWp_-VXath28y0Vy58biCm9sl/view?usp=drive_link\n",
        "# test: https://drive.google.com/file/d/1v7wvkUHj3jm3v40N0u3d340dMKaLamyH/view?usp=drive_link\n",
        "\n",
        "# Run this once to copy the train and validation data to your CoLab environment\n",
        "# !gdown 10dPJKqwVWp_-VXath28y0Vy58biCm9sl\n",
        "# !gdown 1v7wvkUHj3jm3v40N0u3d340dMKaLamyH\n",
        "\n",
        "\n",
        "\n",
        "# # Convert CSV data to NPY array - don't do it yet! - will lose headings\n",
        "# np.save('/content/house_train.npy', csv_train)\n",
        "# np.save('/content/house_test.npy', csv_test)\n",
        "\n",
        "\n",
        "\n",
        "# DL course version (not needed)\n",
        "# Load CSV file\n",
        "# csv_train = np.genfromtxt('/content/house_train.csv', delimiter=',')\n",
        "# csv_test = np.genfromtxt('/content/house_test.csv', delimiter=',')\n",
        "# if not os.path.exists('./Data.zip'):\n",
        "#   !gdown 1HtnCrncY6dFCYqzgPf1HtPVAerTpwFRm\n",
        "#   !unzip Data.zip"
      ],
      "metadata": {
        "id": "wScBGXXFVadm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0PTMJOWqld0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "QQi15F1xRYmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "train = pd.read_csv('/content/house_train.csv')\n",
        "test = pd.read_csv('/content/house_test.csv')\n",
        "\n",
        "# Print the loaded DataFrames\n",
        "print(train, \"\\n\\n\",  test)\n",
        "\n",
        "print(\"Full train dataset shape is {}\".format(train.shape))\n",
        "print(\"Full test dataset shape is {}\".format(test.shape))\n",
        "\n",
        "\n",
        "#Min and max of all non-numerical columns\n",
        "count = 0\n",
        "for col in train.columns:\n",
        "\n",
        "    if train.dtypes[col] != 'object' and col != \"SalePrice\":\n",
        "        print(col)\n",
        "        count += 1\n",
        "        min_value = train[col].min()\n",
        "        max_value = train[col].max()\n",
        "\n",
        "        print(\"Min value of:\",col,\"=\",min_value)\n",
        "        print(\"Max value of:\", col,\"=\",max_value)\n",
        "print(\"No. of numerical columns is \", count)\n",
        "\n",
        "\n",
        "# Listing non-numerical values\n",
        "\n",
        "wordy_cols = []\n",
        "\n",
        "for col in train.columns:\n",
        "\tif train.dtypes[col] == 'object':\n",
        "\t    wordy_cols.append(col)\n",
        "\n",
        "print(wordy_cols, len(wordy_cols))\n",
        "\n",
        "# Dropping columns containing non-numerical values\n",
        "train = train.drop(wordy_cols, axis=1)\n",
        "print(\"Full train dataset shape is {}\".format(train.shape))\n",
        "\n",
        "# # Split training data into X and y\n",
        "# tr_X = train_data[:, :-1]  # not first row (b4 comma), Assumes the last column contains the labels\n",
        "# tr_y = train_data[:, -1]   # Assumes the last column contains the labels\n",
        "\n",
        "\n",
        "\n",
        "# # Save X and y to separate files\n",
        "# np.save('/content/train_data_X.npy', tr_X)\n",
        "# np.save('/content/train_data_y.npy', tr_y)\n",
        "\n",
        "\n",
        "\n",
        "# print(\"testing house_test.npy for nan\", np.isnan(test_data).sum())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Load in the data\n",
        "# train_data_X = np.load('/content/train_data_X.npy',allow_pickle=True)\n",
        "# train_data_y = np.load('/content/train_data_y.npy',allow_pickle=True)\n",
        "# val_data_X = np.load('/content/test_data_X.npy',allow_pickle=True)\n",
        "\n",
        "\n",
        "\n",
        "# print(np.isnan(train_data_X).sum())\n",
        "# print(np.isnan(train_data_y).sum())\n",
        "# print(np.isnan(val_data_X).sum())\n",
        "\n",
        "\n",
        "\n",
        "# # # Print out sizes\n",
        "# print(\"Train data: %d examples (columns), each of which has %d dimensions (rows)\"%((train_data_X.shape[1],train_data_X.shape[0])))\n",
        "# print(\"Validation data: %d examples (columns), each of which has %d dimensions (rows)\"%((val_data_X.shape[1],val_data_X.shape[0])))\n",
        "\n",
        "# print(train_data_y[:10])\n",
        "\n",
        "# print(val_data_y[:10])\n",
        "\n",
        "# print(train_data_X[:10])\n",
        "\n",
        "# print(val_data_X[:10])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8bKADvLHbiV5",
        "outputId": "1900e31d-8c58-4195-e996-4b2c97bf9dea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
            "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
            "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
            "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
            "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
            "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
            "\n",
            "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
            "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
            "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
            "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
            "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "\n",
            "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0         2   2008        WD         Normal     208500  \n",
            "1         5   2007        WD         Normal     181500  \n",
            "2         9   2008        WD         Normal     223500  \n",
            "3         2   2006        WD        Abnorml     140000  \n",
            "4        12   2008        WD         Normal     250000  \n",
            "...     ...    ...       ...            ...        ...  \n",
            "1455      8   2007        WD         Normal     175000  \n",
            "1456      2   2010        WD         Normal     210000  \n",
            "1457      5   2010        WD         Normal     266500  \n",
            "1458      4   2010        WD         Normal     142125  \n",
            "1459      6   2008        WD         Normal     147500  \n",
            "\n",
            "[1460 rows x 81 columns] \n",
            "\n",
            "         Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0     1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
            "1     1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
            "2     1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
            "3     1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
            "4     1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
            "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
            "1454  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n",
            "1455  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n",
            "1456  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n",
            "1457  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n",
            "1458  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n",
            "\n",
            "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
            "0            Lvl    AllPub  ...         120        0    NaN  MnPrv   \n",
            "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
            "2            Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
            "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
            "4            HLS    AllPub  ...         144        0    NaN    NaN   \n",
            "...          ...       ...  ...         ...      ...    ...    ...   \n",
            "1454         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
            "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
            "1456         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
            "1457         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
            "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
            "\n",
            "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
            "0            NaN       0      6    2010        WD         Normal  \n",
            "1           Gar2   12500      6    2010        WD         Normal  \n",
            "2            NaN       0      3    2010        WD         Normal  \n",
            "3            NaN       0      6    2010        WD         Normal  \n",
            "4            NaN       0      1    2010        WD         Normal  \n",
            "...          ...     ...    ...     ...       ...            ...  \n",
            "1454         NaN       0      6    2006        WD         Normal  \n",
            "1455         NaN       0      4    2006        WD        Abnorml  \n",
            "1456         NaN       0      9    2006        WD        Abnorml  \n",
            "1457        Shed     700      7    2006        WD         Normal  \n",
            "1458         NaN       0     11    2006        WD         Normal  \n",
            "\n",
            "[1459 rows x 80 columns]\n",
            "Full train dataset shape is (1460, 81)\n",
            "Full test dataset shape is (1459, 80)\n",
            "Id\n",
            "Min value of: Id = 1\n",
            "Max value of: Id = 1460\n",
            "MSSubClass\n",
            "Min value of: MSSubClass = 20\n",
            "Max value of: MSSubClass = 190\n",
            "LotFrontage\n",
            "Min value of: LotFrontage = 21.0\n",
            "Max value of: LotFrontage = 313.0\n",
            "LotArea\n",
            "Min value of: LotArea = 1300\n",
            "Max value of: LotArea = 215245\n",
            "OverallQual\n",
            "Min value of: OverallQual = 1\n",
            "Max value of: OverallQual = 10\n",
            "OverallCond\n",
            "Min value of: OverallCond = 1\n",
            "Max value of: OverallCond = 9\n",
            "YearBuilt\n",
            "Min value of: YearBuilt = 1872\n",
            "Max value of: YearBuilt = 2010\n",
            "YearRemodAdd\n",
            "Min value of: YearRemodAdd = 1950\n",
            "Max value of: YearRemodAdd = 2010\n",
            "MasVnrArea\n",
            "Min value of: MasVnrArea = 0.0\n",
            "Max value of: MasVnrArea = 1600.0\n",
            "BsmtFinSF1\n",
            "Min value of: BsmtFinSF1 = 0\n",
            "Max value of: BsmtFinSF1 = 5644\n",
            "BsmtFinSF2\n",
            "Min value of: BsmtFinSF2 = 0\n",
            "Max value of: BsmtFinSF2 = 1474\n",
            "BsmtUnfSF\n",
            "Min value of: BsmtUnfSF = 0\n",
            "Max value of: BsmtUnfSF = 2336\n",
            "TotalBsmtSF\n",
            "Min value of: TotalBsmtSF = 0\n",
            "Max value of: TotalBsmtSF = 6110\n",
            "1stFlrSF\n",
            "Min value of: 1stFlrSF = 334\n",
            "Max value of: 1stFlrSF = 4692\n",
            "2ndFlrSF\n",
            "Min value of: 2ndFlrSF = 0\n",
            "Max value of: 2ndFlrSF = 2065\n",
            "LowQualFinSF\n",
            "Min value of: LowQualFinSF = 0\n",
            "Max value of: LowQualFinSF = 572\n",
            "GrLivArea\n",
            "Min value of: GrLivArea = 334\n",
            "Max value of: GrLivArea = 5642\n",
            "BsmtFullBath\n",
            "Min value of: BsmtFullBath = 0\n",
            "Max value of: BsmtFullBath = 3\n",
            "BsmtHalfBath\n",
            "Min value of: BsmtHalfBath = 0\n",
            "Max value of: BsmtHalfBath = 2\n",
            "FullBath\n",
            "Min value of: FullBath = 0\n",
            "Max value of: FullBath = 3\n",
            "HalfBath\n",
            "Min value of: HalfBath = 0\n",
            "Max value of: HalfBath = 2\n",
            "BedroomAbvGr\n",
            "Min value of: BedroomAbvGr = 0\n",
            "Max value of: BedroomAbvGr = 8\n",
            "KitchenAbvGr\n",
            "Min value of: KitchenAbvGr = 0\n",
            "Max value of: KitchenAbvGr = 3\n",
            "TotRmsAbvGrd\n",
            "Min value of: TotRmsAbvGrd = 2\n",
            "Max value of: TotRmsAbvGrd = 14\n",
            "Fireplaces\n",
            "Min value of: Fireplaces = 0\n",
            "Max value of: Fireplaces = 3\n",
            "GarageYrBlt\n",
            "Min value of: GarageYrBlt = 1900.0\n",
            "Max value of: GarageYrBlt = 2010.0\n",
            "GarageCars\n",
            "Min value of: GarageCars = 0\n",
            "Max value of: GarageCars = 4\n",
            "GarageArea\n",
            "Min value of: GarageArea = 0\n",
            "Max value of: GarageArea = 1418\n",
            "WoodDeckSF\n",
            "Min value of: WoodDeckSF = 0\n",
            "Max value of: WoodDeckSF = 857\n",
            "OpenPorchSF\n",
            "Min value of: OpenPorchSF = 0\n",
            "Max value of: OpenPorchSF = 547\n",
            "EnclosedPorch\n",
            "Min value of: EnclosedPorch = 0\n",
            "Max value of: EnclosedPorch = 552\n",
            "3SsnPorch\n",
            "Min value of: 3SsnPorch = 0\n",
            "Max value of: 3SsnPorch = 508\n",
            "ScreenPorch\n",
            "Min value of: ScreenPorch = 0\n",
            "Max value of: ScreenPorch = 480\n",
            "PoolArea\n",
            "Min value of: PoolArea = 0\n",
            "Max value of: PoolArea = 738\n",
            "MiscVal\n",
            "Min value of: MiscVal = 0\n",
            "Max value of: MiscVal = 15500\n",
            "MoSold\n",
            "Min value of: MoSold = 1\n",
            "Max value of: MoSold = 12\n",
            "YrSold\n",
            "Min value of: YrSold = 2006\n",
            "Max value of: YrSold = 2010\n",
            "No. of numerical columns is  37\n",
            "['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition'] 43\n",
            "Full train dataset shape is (1460, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the network"
      ],
      "metadata": {
        "id": "_sFvRDGrl4qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOU SHOULD NOT CHANGE THIS CELL!\n",
        "\n",
        "# There are 40 input dimensions and 10 output dimensions for this data\n",
        "# The inputs correspond to the 40 offsets in the MNIST1D template.\n",
        "D_i = 40\n",
        "# The outputs correspond to the 10 digits\n",
        "D_o = 10\n",
        "\n",
        "# Number of hidden units in layers 1 and 2\n",
        "D_1 = 100\n",
        "D_2 = 100\n",
        "\n",
        "# create model with two hidden layers\n",
        "model = nn.Sequential(\n",
        "nn.Linear(D_i, D_1),\n",
        "nn.ReLU(),\n",
        "nn.Linear(D_1, D_2),\n",
        "nn.ReLU(),\n",
        "nn.Linear(D_2, D_o))"
      ],
      "metadata": {
        "id": "FslroPJJffrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# He initialization of weights\n",
        "def weights_init(layer_in):\n",
        "  if isinstance(layer_in, nn.Linear):\n",
        "    nn.init.kaiming_uniform_(layer_in.weight)\n",
        "    layer_in.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "YgLaex1pfhqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You need all this stuff to ensure that PyTorch is deterministic\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "metadata": {
        "id": "zXRmxCQNnL_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed so always get same result (do not change)\n",
        "set_seed(1)\n",
        "# choose cross entropy loss function (equation 5.24 in the loss notes)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# construct SGD optimizer and initialize learning rate and momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9)\n",
        "\n",
        "\n",
        "# object that decreases learning rate by half every 10 epochs\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "\n",
        "\n",
        "# create 100 dummy data points and store in data loader class\n",
        "x_train = torch.tensor(train_data_x.transpose().astype('float32'))\n",
        "print(x_train.shape)\n",
        "y_train = torch.tensor(train_data_y.astype('long'))\n",
        "print(y_train.shape)\n",
        "x_val= torch.tensor(val_data_x.transpose().astype('float32'))\n",
        "y_val = torch.tensor(val_data_y.astype('long'))\n",
        "\n",
        "# load the data into a class that creates the batches\n",
        "data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=100, shuffle=True, worker_init_fn=np.random.seed(1))\n",
        "\n",
        "# Initialize model weights\n",
        "model.apply(weights_init)\n",
        "\n",
        "# loop over the dataset n_epoch times\n",
        "n_epoch = 50\n",
        "# store the loss and the % correct at each epoch\n",
        "losses_train = np.zeros((n_epoch))\n",
        "errors_train = np.zeros((n_epoch))\n",
        "losses_val = np.zeros((n_epoch))\n",
        "errors_val = np.zeros((n_epoch))\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  # loop over batches\n",
        "  for i, data in enumerate(data_loader):\n",
        "    # retrieve inputs and labels for this batch\n",
        "    x_batch, y_batch = data\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass -- calculate model output\n",
        "    pred = model(x_batch)\n",
        "    # compute the lss\n",
        "    loss = loss_function(pred, y_batch)\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    # SGD update\n",
        "    optimizer.step()\n",
        "\n",
        "  # Run whole dataset to get statistics -- normally wouldn't do this\n",
        "  pred_train = model(x_train)\n",
        "  pred_val = model(x_val)\n",
        "  _, predicted_train_class = torch.max(pred_train.data, 1)\n",
        "  _, predicted_val_class = torch.max(pred_val.data, 1)\n",
        "  errors_train[epoch] = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
        "  errors_val[epoch]= 100 - 100 * (predicted_val_class == y_val).float().sum() / len(y_val)\n",
        "  losses_train[epoch] = loss_function(pred_train, y_train).item()\n",
        "  losses_val[epoch]= loss_function(pred_val, y_val).item()\n",
        "  print(f'Epoch {epoch:5d}, train loss {losses_train[epoch]:.6f}, train error {errors_train[epoch]:3.2f},  val loss {losses_val[epoch]:.6f}, percent error {errors_val[epoch]:3.2f}')\n",
        "\n",
        "  # tell scheduler to consider updating learning rate\n",
        "  scheduler.step()\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(errors_train,'r-',label='train')\n",
        "ax.plot(errors_val,'b-',label='validation')\n",
        "ax.set_ylim(0,100); ax.set_xlim(0,n_epoch)\n",
        "ax.set_xlabel('Epoch'); ax.set_ylabel('Error')\n",
        "ax.set_title('Part II: Validation Result %3.2f'%(errors_val[-1]))\n",
        "ax.legend()\n",
        "ax.plot([0,n_epoch],[37.45, 37.45],'k:') # Original results. You should be better than this!\n",
        "plt.savefig('Coursework_II_Results.png',format='png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NYw8I_3mmX5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leave this all commented for now\n",
        "# We'll see how well you did on the test data after the coursework is submitted\n",
        "\n",
        "# # I haven't given you this yet, leave commented\n",
        "# test_data_x = np.load('test_data_x.npy')\n",
        "# test_data_y = np.load('test_data_y.npy')\n",
        "# x_test = torch.tensor(test_data_x.transpose().astype('float32'))\n",
        "# y_test = torch.tensor(test_data_y.astype('long'))\n",
        "# pred_test = model(x_test)\n",
        "# _, predicted_test_class = torch.max(pred_test.data, 1)\n",
        "# errors_test = 100 - 100 * (predicted_test_class == y_test).float().sum() / len(y_test)\n",
        "# print(\"Test error = %3.3f\"%(errors_test))"
      ],
      "metadata": {
        "id": "O7nBz-R84QdJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}